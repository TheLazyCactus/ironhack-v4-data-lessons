{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f620a4",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[**Introduction to MLFlow and MLOps**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd13b8d",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [**Introduction to MLFlow and MLOps**](#toc1_)    \n",
    "  - [**Why MLFlow?**](#toc1_1_)    \n",
    "  - [**What Can MLFlow Do?**](#toc1_2_)    \n",
    "- [**Hands-On MLFlow**](#toc2_)    \n",
    "  - [**Basic Usage: Autologging**](#toc2_1_)    \n",
    "  - [**Viewing Results Through the UI**](#toc2_2_)    \n",
    "  - [**Creating Experiments and Designing Logic**](#toc2_3_)    \n",
    "  - [**Where Does MLFlow Store Data?**](#toc2_4_)    \n",
    "  - [**Retrieving Models from MLFlow**](#toc2_5_)    \n",
    "  - [**Register models**](#toc2_6_)    \n",
    "  - [**Extra**](#toc2_7_)    \n",
    "    - [**Nested Experiments**](#toc2_7_1_)    \n",
    "    - [**Setting Up AWS Storage**](#toc2_7_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb64df13",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[**Why MLFlow?**](#toc0_)\n",
    "![MLOps](https://raw.githubusercontent.com/dsml-bootcamp-1/nbs-6-master/refs/heads/master/s-601-602/image_ops.png)\n",
    "\n",
    "Machine learning models go through several stages: data preprocessing, training, evaluation, deployment, and monitoring. \n",
    "Ensuring consistency and reproducibility across these stages is a crucial aspect of MLOps (Machine Learning Operations). \n",
    "\n",
    "MLFlow is a tool designed to streamline this process by providing a centralized system to manage and track:\n",
    "- Experiments and their results (e.g., parameters, metrics)\n",
    "- Models and their artifacts (e.g., saved files, plots, images)\n",
    "- Deployment logic for easy retrieval and deployment\n",
    "\n",
    "## <a id='toc1_2_'></a>[**What Can MLFlow Do?**](#toc0_)\n",
    "MLFlow can store:\n",
    "- **Models**: Trained models in various formats (e.g., TensorFlow, PyTorch, Scikit-Learn)\n",
    "- **Parameters**: Hyperparameters used for training\n",
    "- **Metrics**: Evaluation metrics (e.g., accuracy, loss)\n",
    "- **Artifacts**: Additional files (e.g., images, plots, HTML reports)\n",
    "- **Data**: Input and output data (e.g., CSVs, dataframes)\n",
    "\n",
    "![MLFlow Overview](../../../../img/mlflow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MLFlow if not already installed\n",
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mlflow version\n",
    "import mlflow\n",
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc93ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sklearn version\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6729eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the version is higher than 1.0.2, then downgrade (needed for autologging)\n",
    "# !pip install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5ac7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e121a1",
   "metadata": {},
   "source": [
    "### Troubleshooting\n",
    "> `ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc97f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104aa47d",
   "metadata": {},
   "source": [
    "\n",
    "# <a id='toc2_'></a>[**Hands-On MLFlow**](#toc0_)\n",
    "\n",
    "## <a id='toc2_1_'></a>[**Basic Usage: Autologging**](#toc0_)\n",
    "\n",
    "MLFlow provides an easy-to-use `autolog` feature. Let's start by training a simple model and see how MLFlow tracks everything.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install plotly\n",
    "#!pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec423d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import plotly.express as px\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6928ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe0ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X, y split\n",
    "X = pd.DataFrame(data[\"data\"], columns=data.feature_names)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(data.target)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab01cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split - ideal?\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42887156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autologging for Sklearn\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Train a simple model\n",
    "with mlflow.start_run():\n",
    "    # Instantiate and fit classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Add custom metrics - ROC-AUC, PR-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b976617",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"file:///\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2f46b",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_2_'></a>[**Viewing Results Through the UI**](#toc0_)\n",
    "\n",
    "Start the MLFlow UI to visualize your logged experiments:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef6ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in your terminal (not in Jupyter)\n",
    "# mlflow ui\n",
    "\n",
    "# Can also change the port\n",
    "# mlflow ui --port=8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1d2f",
   "metadata": {},
   "source": [
    "\n",
    "Navigate to `http://localhost:5000` to see your experiments.\n",
    "\n",
    "![MLFlow UI Screenshot](https://mlflow.org/docs/latest/_images/quickstart-our-experiment.png) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2277eb0",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_3_'></a>[**Creating Experiments and Designing Logic**](#toc0_)\n",
    "You can explicitly create experiments and log data, custom metrics, tags and other artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae064a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experiment name\n",
    "mlflow.set_experiment(\"breast-cancer-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d695aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccbc668",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df = pd.DataFrame(\n",
    "        {\n",
    "            \"importance\": list(clf.feature_importances_), \n",
    "            \"feature\": list(clf.feature_names_in_)\n",
    "        }\n",
    "    )\n",
    "feat_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log parameters, metrics, and artifacts\n",
    "with mlflow.start_run(run_name=\"Random Forest\"):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Set run tags - features, feature_no, data size\n",
    "    mlflow.set_tag(\"feat_selection\", \"all\")\n",
    "    mlflow.set_tag(\"feature_no\", len(X_train.columns))\n",
    "    mlflow.set_tag(\"features\", X_train.columns.to_list())\n",
    "\n",
    "    # Log predictions\n",
    "    pred = clf.predict_proba(X_test)    \n",
    "    pred_df = pd.DataFrame(pred, columns=[\"prediction_score_0\", \"prediction_score_1\"])\n",
    "    mlflow.log_table(pred_df.reset_index(), artifact_file=\"results/predictions.json\")\n",
    "    \n",
    "    # Log custom metrics manually\n",
    "    mlflow.log_metric(\"ROC-AUC\", roc_auc_score(y_test, pred_df[\"prediction_score_1\"]))\n",
    "    mlflow.log_metric(\"PR-AUC\", average_precision_score(y_test, pred_df[\"prediction_score_1\"]))\n",
    "    \n",
    "    # Log feature importance plot\n",
    "    feat_imp_df = pd.DataFrame(\n",
    "        {\n",
    "            \"importance\": clf.feature_importances_, \n",
    "            \"feature\": clf.feature_names_in_\n",
    "        }\n",
    "    )\n",
    "    feat_imp_df = feat_imp_df.sort_values(by=\"importance\")\n",
    "    fig = px.bar(x=feat_imp_df.importance, y=feat_imp_df.feature)\n",
    "    fig.update_layout(height=800, width=600)\n",
    "    mlflow.log_figure(fig, artifact_file=\"plots/feature_importances.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04499fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict_proba(X_test) \n",
    "pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa2235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Log parameters, metrics, and artifacts\n",
    "with mlflow.start_run(run_name=\"Logistic Regression\"):\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train.iloc[:, :-2], y_train)\n",
    "    \n",
    "    # Set run tags - features, feature_no, data size\n",
    "    mlflow.set_tag(\"feat_selection\", \"manual\")\n",
    "    mlflow.set_tag(\"feature_no\", len(X_train.iloc[:, :-2].columns))\n",
    "    mlflow.set_tag(\"features\", X_train.iloc[:, :-2].columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049aecf",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_4_'></a>[**Where Does MLFlow Store Data?**](#toc0_)\n",
    "\n",
    "Depending on the backend setup, MLFlow stores data in:\n",
    "- **Local filesystem** (e.g., `./mlruns` directory, suitable for quick tests but slow)\n",
    "- **Local SQLite Database**: Lightweight and easy to set up\n",
    "- **Cloud storage**: AWS S3, Google Cloud Storage, etc., for large-scale deployments\n",
    "\n",
    "To configure MLFlow to use a SQLite backend:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d89f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example command to run in terminal (not in Jupyter)\n",
    "# mlflow server/ui \\\n",
    "#    --backend-store-uri sqlite:///mlflow.db \\\n",
    "#    --default-artifact-root ./mlruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb4b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check where experiments are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911abe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tracking uri\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "mlflow.set_experiment(\"breast-cancer-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad7387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log parameters, metrics, and artifacts\n",
    "for i in range(1, 11):\n",
    "    with mlflow.start_run(run_name=\"Random Forest\"):\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        clf.fit(X_train.iloc[:, :i], y_train)\n",
    "        mlflow.sklearn.log_model(clf, artifact_path=\"my_model\")\n",
    "\n",
    "        # Set run tags - features, feature_no, data size\n",
    "        mlflow.set_tag(\"feat_selection\", \"sequential\")\n",
    "        mlflow.set_tag(\"feature_no\", len(X_train.iloc[:, :i].columns))\n",
    "        mlflow.set_tag(\"features\", X_train.iloc[:, :i].columns.to_list())\n",
    "\n",
    "        # Log predictions\n",
    "        pred = clf.predict_proba(X_test.iloc[:, :i])    \n",
    "        pred_df = pd.DataFrame(pred, columns=[\"prediction_score_0\", \"prediction_score_1\"])\n",
    "        mlflow.log_table(pred_df.reset_index(), artifact_file=\"results/predictions.json\")\n",
    "\n",
    "        # Log custom metrics manually\n",
    "        mlflow.log_metric(\"ROC-AUC\", roc_auc_score(y_test, pred_df[\"prediction_score_1\"]))\n",
    "        mlflow.log_metric(\"PR-AUC\", average_precision_score(y_test, pred_df[\"prediction_score_1\"]))\n",
    "\n",
    "        # Log feature importance plot\n",
    "        feat_imp_df = pd.DataFrame(\n",
    "            {\n",
    "                \"importance\": clf.feature_importances_, \n",
    "                \"feature\": clf.feature_names_in_\n",
    "            }\n",
    "        )\n",
    "        feat_imp_df = feat_imp_df.sort_values(by=\"importance\")\n",
    "        fig = px.bar(x=feat_imp_df.importance, y=feat_imp_df.feature)\n",
    "        fig.update_layout(height=800, width=600)\n",
    "        mlflow.log_figure(fig, artifact_file=\"plots/feature_importances.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9b232",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_5_'></a>[**Retrieving Models from MLFlow**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa557085",
   "metadata": {},
   "source": [
    "Search through models - more filtering tips [here](https://mlflow.org/docs/latest/search-runs.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f139c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search all runs with PR-AUC higher than 0.7\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_names=[\"breast-cancer-classification\"],\n",
    "    filter_string=\"\"\"metrics.`ROC-AUC` > 0.99\n",
    "    AND tags.feat_selection LIKE 'sequential'\n",
    "    \"\"\"\n",
    ")\n",
    "runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66ca01",
   "metadata": {},
   "source": [
    "You can load previously saved models for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model is stored under the model folder by the sklearn autologging, but\n",
    "# I can save it anywhere\n",
    "mlflow.log_model(clf, artifact_path=\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f064c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model using run_id\n",
    "run_id = \"018dd9c9aec8463a8eec9fd44ddb98be\"\n",
    "model_uri = f\"runs:/{run_id}/model\"  # Replace <run_id> with an actual run ID\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# Use the model for predictions\n",
    "loaded_model.predict(X_test.iloc[:, :7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae744cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict_proba(X_test.iloc[:, :7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d164a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.fit(X_test.iloc[:, :-7], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a73f58",
   "metadata": {},
   "source": [
    "## <a id='toc2_6_'></a>[**Register models**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d51a5",
   "metadata": {},
   "source": [
    "This can be done either through the UI or via code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model using runs:/ location\n",
    "mlflow.register_model(model_uri=f\"runs:/{run_id}/model\", name=\"breast-cancer-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf57a9",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_7_'></a>[**Extra**](#toc0_)\n",
    "\n",
    "### <a id='toc2_7_1_'></a>[**Nested Experiments**](#toc0_)\n",
    "MLFlow allows nested runs for tracking hierarchical experiments. This can be useful if you want to group results from cross-validation folds in separate runs but keep the same attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create stratified KFold\n",
    "cross_validator = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_splits = cross_validator.split(X, y)\n",
    "\n",
    "for train_indices, test_indices in cv_splits:\n",
    "    print(train_indices)\n",
    "    print(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac08299",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, elem in enumerate([\"red\", \"brown\", \"blue\"]):\n",
    "    print(i, elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nested cross-validation\n",
    "mlflow.sklearn.autolog(disable=False)\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "mlflow.set_experiment('breast-cancer-classification')\n",
    "\n",
    "with mlflow.start_run(run_name=\"Random Forest\", nested=True) as parent_run:\n",
    "    # Log features\n",
    "    \n",
    "    for i, (train_split, test_split) in enumerate(cv_splits):\n",
    "        with mlflow.start_run(run_name=f\"Random Forest {i}\", nested=True):\n",
    "            # New train-test split\n",
    "            \n",
    "            clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Use same logging as before\n",
    "            mlflow.set_tag(\"fold\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc7873e",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc2_7_2_'></a>[**Setting Up AWS Storage**](#toc0_)\n",
    "You can configure MLFlow to use AWS Postgresql database (either on RDS or Redshift) as metadata store and AWS S3 as the artifact storage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f7dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in terminal\n",
    "# !mlflow server/ui \\\n",
    "#     --backend-store-uri 'postgresql://user_name:password@link_to_your_aws_postgresql_db:port' \\\n",
    "#     --default-artifact-root s3://your-bucket-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"postgresql://user_name:password@link_to_your_aws_postgresql_db:port\")\n",
    "mlflow.create_experiment(\"name\", artifact_location=\"s3://your-bucket-name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
