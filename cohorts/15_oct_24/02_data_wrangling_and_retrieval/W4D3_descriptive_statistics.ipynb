{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb77cd5d",
   "metadata": {},
   "source": [
    "# Descriptive Statistics Notebook\n",
    "\n",
    "## Index\n",
    "\n",
    "1. [Central Location Measures](#Location-Measures)\n",
    "    - Mean\n",
    "    - Median\n",
    "    - Mode\n",
    "\n",
    "2. [Non- central Location Measurres](#Non-Central-Location-Measures)\n",
    "    - Min, max\n",
    "    - Quartiles\n",
    "    - Percentiles\n",
    "\n",
    "3. [Dispersion Measures](#Dispersion-Measures)\n",
    "    - IQR - Inter Quartile Range\n",
    "    - Variance\n",
    "    - Standard Deviation\n",
    "    - Coeficient of Variation\n",
    "    - Advanced - Extra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce67e02d",
   "metadata": {},
   "source": [
    "# Central Location Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea885e",
   "metadata": {},
   "source": [
    "## Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1714200010839,
     "user": {
      "displayName": "Gonçalo Jardim",
      "userId": "12269190236703436081"
     },
     "user_tz": -60
    },
    "id": "tEnIyrm56s2j",
    "outputId": "4ea976da-60f6-46fc-fe25-968510f1fe4c"
   },
   "outputs": [],
   "source": [
    "dataset = np.random.randint(20,80,size = 500)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1714200019605,
     "user": {
      "displayName": "Gonçalo Jardim",
      "userId": "12269190236703436081"
     },
     "user_tz": -60
    },
    "id": "FhF5VHzp63uj",
    "outputId": "81fb62b7-9eb7-45b5-b122-d478422c883d"
   },
   "outputs": [],
   "source": [
    "# calculate the mean/average\n",
    "\n",
    "mean = (np.sum(dataset))/len(dataset)\n",
    "print(mean)\n",
    "\n",
    "# there is a function for this in numpy\n",
    "print(dataset.mean())\n",
    "\n",
    "# mean is a measure of location/center\n",
    "# problem of mean: it is very sensitive to outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b9872d",
   "metadata": {},
   "source": [
    "## Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1714200040559,
     "user": {
      "displayName": "Gonçalo Jardim",
      "userId": "12269190236703436081"
     },
     "user_tz": -60
    },
    "id": "5hx4RyYB8LdC",
    "outputId": "1ffbf339-a45c-46c4-9bfb-993fbbabc8b3"
   },
   "outputs": [],
   "source": [
    "# median -> the central number/ middle value\n",
    "# understand why the median is barely affected by outliers\n",
    "# because outliers only count as \"one more element\" and barely change the center\n",
    "print(np.sort(dataset)[5])\n",
    "print(np.sort(dataset)[6])\n",
    "print(np.median(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894d6d25",
   "metadata": {},
   "source": [
    "## Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1094,
     "status": "ok",
     "timestamp": 1714200053134,
     "user": {
      "displayName": "Gonçalo Jardim",
      "userId": "12269190236703436081"
     },
     "user_tz": -60
    },
    "id": "fPayHz2L88yw",
    "outputId": "67dfc9a6-dcd3-47e1-8a58-8ad4f618eb40"
   },
   "outputs": [],
   "source": [
    "# mode is the most frequent value aka: the one that appears the most\n",
    "# numpy doesnt have an easy mode function\n",
    "# https://www.scipy.org/\n",
    "from scipy import stats\n",
    "\n",
    "stats.mode(dataset)\n",
    "#mode method returns 2 elements -> the mode, and the count of that element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1714200056494,
     "user": {
      "displayName": "Gonçalo Jardim",
      "userId": "12269190236703436081"
     },
     "user_tz": -60
    },
    "id": "yWiHrtvH1yt7",
    "outputId": "521e968a-a6f9-4219-9348-cb36841bda03"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Central Location Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.min())\n",
    "print(dataset.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quartiles and percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculated the lower quartile -> the position where 25% of my data \"has passed\"\n",
    "q1 = np.quantile(dataset, 0.25)#, interpolation='midpoint')\n",
    "print(\"the first quartile is\", q1)\n",
    "q2 = np.quantile(dataset, 0.50)\n",
    "print(\"the second quartile is\",q2)\n",
    "q3 = np.quantile(dataset, 0.75)\n",
    "print(\"the third quartile is\", q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting histograms allows us to visualize nicely the distribution of our data\n",
    "# this histograms creates \"buckets/boxes\" of values and then places the numbers of the dataset in each box and counts\n",
    "plt.hist(dataset, bins = 20)\n",
    "#plt.show()\n",
    "\n",
    "#plt.hist(dataset, bins = 20, cumulative = True)\n",
    "#plt.hlines([125,250,375],20,85,colors = 'r')\n",
    "plt.vlines([q1,q2,q3],0,500,colors='r', label= [q1,q2,q3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the box plot brings together all this information\n",
    "plt.boxplot(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb39e2",
   "metadata": {},
   "source": [
    "# Dispersion Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IQR - Inter Quartile Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interquartile Range\n",
    "\n",
    "# range\n",
    "print(dataset.max() - dataset.min())\n",
    "\n",
    "# what information does the IQR give you about how spread out the data is?\n",
    "# between the upper quartile and the lower quartile lies for sure 50% of the data\n",
    "#it's a measure of how spread out, 50% of the data is?\n",
    "iqr = q3 - q1\n",
    "print(iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset-np.mean(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.square(dataset-np.mean(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance\n",
    "\n",
    "# we square the differences between the mean and each point\n",
    "squared_differences = np.square(dataset-np.mean(dataset))\n",
    "variance = np.sum(squared_differences)/len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the variance a meaningful indicator? why?\n",
    "# the units of the variance are the square of the units of each elements\n",
    "# makes it hard to relate to the average.\n",
    "\n",
    "standard_deviation = np.sqrt(variance)\n",
    "\n",
    "\n",
    "\n",
    "# the standard deviation has the correct units compared to each element\n",
    "\n",
    "print(\"\"\"The \"typical\" variation of ages in this data set is \"\"\", standard_deviation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(dataset)/np.mean(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(dataset2)/np.mean(dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient of Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficient of variation. standard deviation as percentage of mean\n",
    "\n",
    "cv = standard_deviation/np.mean(dataset)\n",
    "print(cv)\n",
    "\n",
    "#big advantage -> this indicator has no units -> its a relative indicator\n",
    "# very useful when comparing the variations of measures with different units\n",
    "\n",
    "#e.g.\n",
    "#webdev cohort std of height = 20 cm\n",
    "#cv_webdev = 35%\n",
    "#data cohort std of ages = 4 years\n",
    "#cv_data = 15%\n",
    "#what has more variation? heights in webdev of ages in data?\n",
    "#based on CV I can say that ages in data, has less variation than heights in webdev\n",
    "\n",
    "\n",
    "\n",
    "# one BIG disadvantage of CV -> non-linear data transformations\n",
    "\n",
    "# these numbers are exactly the same but in two different scales\n",
    "# celsius faranheit scale example  D*(9/5) + 32 = F\n",
    "\n",
    "Celsius =  [0, 10, 20, 30, 40]\n",
    "Fahrenheit =  [32, 50, 68, 86, 104]\n",
    "\n",
    "print(np.std(Celsius)/np.mean(Celsius))\n",
    "print(np.std(Fahrenheit)/np.mean(Fahrenheit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75ed14c",
   "metadata": {},
   "source": [
    "### Advanced - Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADVANCED: Rankine is to Farenheight what Kelvin is to Celsius (-273.15), which means there is a linear relation between Kelvin and Rankine\n",
    "#(9/5) to be exact\n",
    "Kelvin = [273.15, 283.15, 293.15, 303.15, 313.15]\n",
    "Rankine = [491.67, 509.67, 527.67, 545.67, 563.67]\n",
    "#print(np.divide(np.array(Rankine),np.array(Kelvin)))\n",
    "\n",
    "print(np.std(Kelvin)/np.mean(Kelvin))\n",
    "print(np.std(Rankine)/np.mean(Rankine))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
