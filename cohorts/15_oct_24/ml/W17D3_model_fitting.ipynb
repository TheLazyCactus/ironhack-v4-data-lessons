{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Bias-variance trade-off](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Bias-variance trade-off](#toc1_)    \n",
    "  - [What is bias?](#toc1_1_)    \n",
    "  - [What is variance?](#toc1_2_)    \n",
    "  - [Extra: The maths of it all  ](#toc1_3_)    \n",
    "    - [What is noise?](#toc1_3_1_)    \n",
    "  - [What do want and how to get there?](#toc1_4_)    \n",
    "    - [Regularization](#toc1_4_1_)    \n",
    "      - [Train Test Split](#toc1_4_1_1_)    \n",
    "    - [Baseline](#toc1_4_2_)    \n",
    "    - [Revisit Train-Test split](#toc1_4_3_)    \n",
    "    - [Review overfitting across multiple parameters](#toc1_4_4_)    \n",
    "- [Resources](#toc2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/v2/resize:fit:828/format:webp/1*9hPX9pAO3jqLrzt0IE3JzA.png)  \n",
    "(Source: [Understanding the Bias-Variance Tradeoff, Medium](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[What is bias?](#toc0_)\n",
    "\n",
    "**Bias is how wrong our model is on average.** \n",
    "\n",
    "In maths terms, bias is the difference between our models predictions and the correct answer. A model has **high bias** if its predictions are very far off from the truth, typically because the model is too simple or the data seen by the model is not representative of the real data. \n",
    "\n",
    "If the issue is the model, we say that the model is **underfit** and even if we give the model more data, because it's so simple, it still can't learn. That's sad but don't worry, simple models are still good for a variety of tasks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[What is variance?](#toc0_)\n",
    "\n",
    "**Variance is how different the predictions of our model are for the SAME type of data.** \n",
    "\n",
    "Imagine our house price predictor. If we train a model which has a high variance, it could tell us that a house with 3 rooms is $100,000 and one with 4 rooms is $500,000. Yikes! \n",
    "\n",
    "You notice the variance of a model when you look at an accuracy metric on 2 different sets, usually the train and test set (later on, train and validation...). \n",
    "* If the difference is high, the model has **high variance**, i.e. it memorized the data and didn't learn much, like a student who thinks they had the answer to the test but then sit the exam and get a bad score. The model is **overfit**.\n",
    "* If the difference is low, the model has **low variance**, i.e. it learnt the main patterns in the data, like a student who studied the lessons and not the test answers! The model is neither overfit or underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Extra: The maths of it all](https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote12.html)   [&#8593;](#toc0_)\n",
    "\n",
    "$\\underbrace{E_{\\mathbf{x}, y, D} \\left[\\left(h_{D}(\\mathbf{x}) - y\\right)^{2}\\right]}_\\mathrm{Expected\\;Test\\;Error} = \\underbrace{E_{\\mathbf{x}, D}\\left[\\left(h_{D}(\\mathbf{x}) - \\bar{h}(\\mathbf{x})\\right)^{2}\\right]}_\\mathrm{Variance} + \\underbrace{E_{\\mathbf{x}, y}\\left[\\left(\\bar{y}(\\mathbf{x}) - y\\right)^{2}\\right]}_\\mathrm{Noise} + \\underbrace{E_{\\mathbf{x}}\\left[\\left(\\bar{h}(\\mathbf{x}) - \\bar{y}(\\mathbf{x})\\right)^{2}\\right]}_\\mathrm{Bias^2}$\n",
    "\n",
    "### <a id='toc1_3_1_'></a>[What is noise?](#toc0_)\n",
    "\n",
    "It's the stuff you can't predict. As you already know, models are not perfect representations of reality. If we were able to perfectly model the universe, we wouldn't need Machine Learning and our noise or error would be 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[What do want and how to get there?](#toc0_)\n",
    "\n",
    "A model complex enough to understand the data but not so complex that it memorizes the data.\n",
    "\n",
    "![](http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png)  \n",
    "\n",
    "(Source: [Understanding the Bias-Variance Tradeoff, Scott Fortmann-Roe](https://scott.fortmann-roe.com/docs/BiasVariance.html))\n",
    "\n",
    "When spotting overfitting, we can deal with it in a number of ways:\n",
    "- Reduce model complexity\n",
    "    - Tweak hyperparameters, e.g. choose lower `max_depth`, `n_estimators`, etc.\n",
    "    - Choose a simpler model, e.g. Linear/Logistic Regression\n",
    "- Apply regulatization, i.e. L1 and L2 regularization\n",
    "- Remove redundant features\n",
    "- **Last resort**: Use more training data\n",
    "    - readily available solution: move from a 80/20 split to a 85/15 or 90/10 split. Do NOT go beyond a 90/10 split.   \n",
    "    **Caveat**: If you have a lot of data, e.g. >10,000 rows, you can start off with a 90/10 split or go beyond the 90/10 split.\n",
    "    - more costly: gather more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_1_'></a>[Regularization](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import  fetch_california_housing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california = fetch_california_housing()\n",
    "print(california[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cali = pd.DataFrame(california[\"data\"], columns = california[\"feature_names\"])\n",
    "df_cali[\"median_house_value\"] = california[\"target\"]\n",
    "\n",
    "df_cali.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_1_1_'></a>[Train Test Split](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_cali.drop(columns = [\"median_house_value\",\"AveOccup\", \"Population\", \"AveBedrms\"])\n",
    "target = df_cali[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_2_'></a>[Baseline](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(n_estimators=20, max_depth=10, random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "print(\"Train Score\", forest.score(X_train, y_train))\n",
    "print(\"Test Score\", forest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_3_'></a>[Revisit Train-Test split](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cali.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20640 * 0.1 # 2K samples to test on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.9, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(n_estimators=20, max_depth=10, random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "print(\"Train Score\", forest.score(X_train, y_train))\n",
    "print(\"Test Score\", forest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_4_'></a>[Review overfitting across multiple parameters](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for n_estimators in range(10, 100, 10):\n",
    "    result = {}\n",
    "    forest = RandomForestRegressor(n_estimators=n_estimators, max_depth=10, random_state=42)\n",
    "    forest.fit(X_train, y_train)\n",
    "\n",
    "    result[\"Score\"] = forest.score(X_train, y_train)\n",
    "    result[\"Set\"] = \"Train Set\"\n",
    "    result[\"Parameter\"] = n_estimators\n",
    "    results = pd.concat([results, pd.DataFrame([result])], axis=0)\n",
    "\n",
    "    result[\"Score\"] = forest.score(X_test, y_test)\n",
    "    result[\"Set\"] = \"Test Set\"\n",
    "    results = pd.concat([results, pd.DataFrame([result])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(results, y=\"Score\", x=\"Parameter\", color=\"Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for max_depth in range(1, 20, 2):\n",
    "    result = {}\n",
    "    forest = RandomForestRegressor(n_estimators=20, max_depth=max_depth, random_state=42)\n",
    "    forest.fit(X_train, y_train)\n",
    "\n",
    "    result[\"Score\"] = forest.score(X_train, y_train)\n",
    "    result[\"Set\"] = \"Train Set\"\n",
    "    result[\"Parameter\"] = max_depth\n",
    "    results = pd.concat([results, pd.DataFrame([result])], axis=0)\n",
    "\n",
    "    result[\"Score\"] = forest.score(X_test, y_test)\n",
    "    result[\"Set\"] = \"Test Set\"\n",
    "    results = pd.concat([results, pd.DataFrame([result])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(results, y=\"Score\", x=\"Parameter\", color=\"Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for min_samples_split in range(10, 100, 10):\n",
    "    result = {}\n",
    "    forest = RandomForestRegressor(n_estimators=20, max_depth=7, random_state=42, min_samples_split=min_samples_split)\n",
    "    forest.fit(X_train, y_train)\n",
    "\n",
    "    result[\"Score\"] = forest.score(X_train, y_train)\n",
    "    result[\"Set\"] = \"Train Set\"\n",
    "    result[\"Parameter\"] = min_samples_split\n",
    "    results = pd.concat([results, pd.DataFrame([result])], axis=0)\n",
    "\n",
    "    result[\"Score\"] = forest.score(X_test, y_test)\n",
    "    result[\"Set\"] = \"Test Set\"\n",
    "    results = pd.concat([results, pd.DataFrame([result])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(results, y=\"Score\", x=\"Parameter\", color=\"Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Resources](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* StatQuest:\n",
    "    * [Bias & Variance](https://www.youtube.com/watch?v=EuBBz3bI-aA) - 6 min"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lizzy_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
