{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZl6x21RYTwt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyGc-ug-FQg7"
      },
      "outputs": [],
      "source": [
        "text= \"\"\"US President Joe Biden says his administration is looking into what happened at a food distribution site in Gaza — where local health officials say more than 100 people were killed and hundreds more injured — and he admitted the incident is going to complicate negotiations in the region.\n",
        "\n",
        "“We’re checking that out right now; there are two competing versions of what happened. I don’t have an answer yet,” the president told CNN’s Arlette Saenz at the White House on Thursday.\n",
        "\n",
        "Asked by Saenz if he worried the deaths would complicate negotiations, he responded: “Oh, I know it will.”\n",
        "\n",
        "But Biden still expressed optimism that a deal on the hostages and a potential ceasefire could be reached soon. \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDzmoXCosE-6"
      },
      "outputs": [],
      "source": [
        "text=\"\"\"President-elect Joe Biden and his transition team are preparing for an early, all-out push to pass an ambitious new stimulus bill, while also drawing up plans for a flurry of executive actions aimed at delivering on campaign promises and undoing the Trump administration's efforts to undermine key government agencies.\n",
        "Biden will be inaugurated in January with a pressing mandate to confront simultaneous and interwoven public health, economic and racial crises. At the same time, his team will take over the work of spearheading one of the most complicated, politically fraught mass vaccination campaigns in American history.\n",
        "Biden's agenda for his first 100 days in office will, according to both those close to him and outside groups in contact with his top aides, center on two key avenues of action: the passage of a broad economic aid package and, where legislation is not necessary, a series of executive actions aimed at advancing his priorities. Containing the Covid-19 pandemic, launching an economic recovery and tackling racial inequality are his most urgent priorities, transition officials say.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLjXsXqzacqc",
        "outputId": "780db1c0-bbf7-418b-a3bc-3a1ba26af856"
      },
      "outputs": [],
      "source": [
        "# this performs word tokenization -> this is used in simple models where each word is a feature\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "tokens[-30:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8ebc1CTzigA",
        "outputId": "59444b49-d6f5-4b88-c233-23fffcb4973b"
      },
      "outputs": [],
      "source": [
        "# we often remove punctuation after tokenization since punctuation is unlikely to be a good predictive feature\n",
        "tokens = [word for word in tokens if word.isalnum()]\n",
        "tokens[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci7FNYAGbZV7",
        "outputId": "1fb12d82-4538-43ff-ca2a-a98b7ad259a3"
      },
      "outputs": [],
      "source": [
        "# Alternative\n",
        "# this performs sentence tokenizations -> can be used if you want to treat each sentence as a \"feature\"\n",
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AMgqkEesfqr",
        "outputId": "59e5ba76-4580-436e-fcce-7809a2df8dde"
      },
      "outputs": [],
      "source": [
        "# Part of speech can be a useful feature in itself, but is also heavily used in making lemmatization and stemming more effective\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.pos_tag(tokens,lang='eng')[:15]\n",
        "#explanation of all these codes can be found here: https://medium.com/@gianpaul.r/tokenization-and-parts-of-speech-pos-tagging-in-pythons-nltk-library-2d30f70af13b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpq-YUJ7fc6t",
        "outputId": "dcb724ac-f23b-4d74-81da-da7b232b15aa"
      },
      "outputs": [],
      "source": [
        "# stemming can be done as cleaning technique -> treats prefixes and suffixes.\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "stemmed = [ps.stem(w) for w in tokens]\n",
        "stemmed[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEgJ4I8Hgo28",
        "outputId": "397839d3-2692-4624-bea4-15f4cba5d796"
      },
      "outputs": [],
      "source": [
        "# lemmatization is a more context aware version of stemming, where we take the actual roots of individual words\n",
        "# the problem is that such a dictionary may not exist for all languages and that it does not know what to do with new words\n",
        "nltk.download('wordnet') # wordnet is the most well known lemmatizer for english\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "lemmatized[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "jHC45jlvuyN6",
        "outputId": "12626329-91a9-455e-f140-78ab639c160a"
      },
      "outputs": [],
      "source": [
        "# lemmatization may still be a bit weak, mostly because the lemmatizer would like a bit more information about context to make decisions\n",
        "display(lemmatizer.lemmatize(\"was\"))\n",
        "display(lemmatizer.lemmatize(\"was\",wordnet.VERB))\n",
        "display(lemmatizer.lemmatize(\"better\"))\n",
        "display(lemmatizer.lemmatize(\"better\",wordnet.ADJ))\n",
        "display(lemmatizer.lemmatize(\"canning\"))\n",
        "display(lemmatizer.lemmatize(\"canning\",wordnet.NOUN))\n",
        "display(lemmatizer.lemmatize(\"canning\",wordnet.VERB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P6i0MpYrawb",
        "outputId": "6bec4d8d-da3a-4d65-ba63-fa5f2b258c5f"
      },
      "outputs": [],
      "source": [
        "# let's apply this to the all the newsfeed\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# unfortunately pos_tag and lemmatize use different codes for parts of speech\n",
        "def get_wordnet_pos(word):\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper() # gets first letter of POS categorization\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN) # get returns second argument if first key does not exist\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized = [lemmatizer.lemmatize(word,get_wordnet_pos(word)) for word in tokens]\n",
        "lemmatized[:15]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPRDgJFo0cCw",
        "outputId": "959aee89-7c57-467b-e8c2-8e1e89416e2b"
      },
      "outputs": [],
      "source": [
        "#removal of stopwords allows us to reduce the noise in the data to focus on the signal\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "without_sw = [word for word in lemmatized if not word in stopwords.words()]\n",
        "without_sw[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "BCBqKEUP36wf",
        "outputId": "6ae6beed-5b58-4efe-acae-aceff6e88422"
      },
      "outputs": [],
      "source": [
        "\" \".join(without_sw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iQ4dR4FEZ65J",
        "outputId": "b2dbd7ff-7757-46f0-d4ca-8a502adc2f89"
      },
      "outputs": [],
      "source": [
        "text.split('.')[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh709ylUdQw1",
        "outputId": "2aa18313-ff43-47ba-d3e2-7523a25f38bb"
      },
      "outputs": [],
      "source": [
        "without_sw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Oqk5EIM915rt",
        "outputId": "3c4b6419-6c97-4cb1-c3d5-3eb03b395a59"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow_vect = CountVectorizer()\n",
        "# fit creates one entry for each different word seen\n",
        "bow_vect.fit([\" \".join(without_sw)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL0968bwds6q",
        "outputId": "4dfda9a8-f5c9-4d7d-9115-5a036b089cc5"
      },
      "outputs": [],
      "source": [
        "set(without_sw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWcjuCLI1ny4",
        "outputId": "5d9a4519-c2dc-497c-8729-681eb024b054"
      },
      "outputs": [],
      "source": [
        "bow_vect.transform(['Joe Biden transition team prepare early push ambitious stimulus bill draw plan flurry executive action aim deliver campaign promise undo Trump administration effort undermine key government agency']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2s4dykkqL19",
        "outputId": "6b179e94-3384-42ac-ce1b-97880860e7e6"
      },
      "outputs": [],
      "source": [
        "bow_vect.transform(['economic economic']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgMKeihKhKfH",
        "outputId": "05e505aa-bff9-4e99-e7d9-c182e8a8ad73"
      },
      "outputs": [],
      "source": [
        "bow_vect.transform(['Joe work ambitious ambitious ambitoud economic rabbit']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewJAxZOqSriL",
        "outputId": "2e2ca413-5680-4392-8b7e-56e47b22c482"
      },
      "outputs": [],
      "source": [
        "bow_vect.transform(['100']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcQpNkUfeabH",
        "outputId": "52d7c1b9-09fd-4f79-821a-534b5cc58bf1"
      },
      "outputs": [],
      "source": [
        "bow_vect.transform(['goncalo']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNkASYyV2DH3",
        "outputId": "3e9df696-3584-4f5f-fa0c-8cf737135175"
      },
      "outputs": [],
      "source": [
        "#transform only considers the words that have been seen in fit\n",
        "bow_vect.transform(['accord stimulus bill bill goncalo']).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2O3h0Cztetj"
      },
      "source": [
        "# News clustering example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "YgOIJ55E15xv",
        "outputId": "a92426dc-49ab-437a-fd4b-14098c81a894"
      },
      "outputs": [],
      "source": [
        "# corpus of 120k news headlines, here shortened to 10k\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GoncaloJardim/ironhack-v4-data-lessons/main/data/news.csv\"\n",
        "\n",
        "all_news = pd.read_csv(url)\n",
        "all_news.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6GIucs6We0f",
        "outputId": "76d79895-6c0d-4abc-8e46-dc0cc2180db2"
      },
      "outputs": [],
      "source": [
        "all_news.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "A1yquYlKtKt-",
        "outputId": "48a49f99-f646-4970-9086-4ba0ad952e7b"
      },
      "outputs": [],
      "source": [
        "all_news.iloc[3]['news']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "XCzORQ3jEvcE",
        "outputId": "8ad04b7e-b777-4191-ad83-1af3cd7bcacf"
      },
      "outputs": [],
      "source": [
        "# same process as before, but for all lines\n",
        "#tokenize, lowercase, remove punctuation\n",
        "\n",
        "def tokenizer_and_remove_punctuation(row):\n",
        "  tokens = word_tokenize(row['news'])\n",
        "  return [word.lower() for word in tokens if word.isalpha()]\n",
        "\n",
        "all_news['tokenized'] = all_news.apply(tokenizer_and_remove_punctuation,axis=1)\n",
        "all_news.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "HnvmW_m_Eve8",
        "outputId": "27f13363-669a-447e-9a66-55d58670c9bd"
      },
      "outputs": [],
      "source": [
        "# lemmatize with part of speech helpers\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatizer_with_pos(row):\n",
        "  return [lemmatizer.lemmatize(word,get_wordnet_pos(word)) for word in row['tokenized']]\n",
        "\n",
        "all_news['lemmatized'] = all_news.apply(lemmatizer_with_pos,axis=1)\n",
        "all_news.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "vViv80x-GsAT",
        "outputId": "077c4915-caf0-41a1-c4e6-e038a45f3d33"
      },
      "outputs": [],
      "source": [
        "# remove stopwords\n",
        "\n",
        "def remove_sw(row):\n",
        "  return list(set(row['lemmatized']).difference(stopwords.words()))\n",
        "\n",
        "all_news['no_stopwords'] = all_news.apply(remove_sw,axis=1)\n",
        "all_news.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "CX2m2ZQQLYqo",
        "outputId": "feef0b18-2255-41b8-cd24-467d7cd72731"
      },
      "outputs": [],
      "source": [
        "# put all this cleaning together\n",
        "\n",
        "def re_blob(row):\n",
        "  return \" \".join(row['no_stopwords'])\n",
        "\n",
        "all_news['clean_blob'] = all_news.apply(re_blob,axis=1)\n",
        "all_news.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ4qJpciFrsS"
      },
      "outputs": [],
      "source": [
        "#let's take only the most common 1000 words\n",
        "bow_vect = CountVectorizer(max_features=1000)\n",
        "# fit creates one entry for each different word seen\n",
        "X = bow_vect.fit_transform(all_news['clean_blob']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VjLymaHbgcl0",
        "outputId": "6301f902-be38-4020-decc-04da401acb2d"
      },
      "outputs": [],
      "source": [
        "all_news['clean_blob'].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "T803D7rhFrva",
        "outputId": "710a14d6-2d61-407d-9fa0-ed277b5fe33b"
      },
      "outputs": [],
      "source": [
        "as_df = pd.DataFrame(X,columns=bow_vect.get_feature_names_out())\n",
        "as_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY1KjIAuFr2V",
        "outputId": "1a59bf28-4207-47df-c915-a4fef797ee92"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=6,random_state=100)\n",
        "kmeans.fit(X)\n",
        "pred = kmeans.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "vV4UfDknFr6s",
        "outputId": "7fbb3921-0353-4ed6-aec8-b1a1a2bd9bf6"
      },
      "outputs": [],
      "source": [
        "predict_df = pd.concat([all_news['news'],pd.DataFrame(pred,columns=['class'])],axis=1)\n",
        "predict_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOIylt7Alfnz"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "_ACgfNccRG2W",
        "outputId": "fc48ae2e-b165-42fe-addc-02d45576b9cd"
      },
      "outputs": [],
      "source": [
        "#sports\n",
        "predict_df[predict_df['class']==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "Ag0fW6pWQ28G",
        "outputId": "a71a14a6-c599-4683-e9af-6979fbd6cc92"
      },
      "outputs": [],
      "source": [
        "#financial\n",
        "predict_df[predict_df['class']==1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "N_HN_-vNPLye",
        "outputId": "067e5e76-ce98-4c56-e1b9-ce13facbf079"
      },
      "outputs": [],
      "source": [
        "#political news\n",
        "predict_df[predict_df['class']==3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "SplXmrDDxL2s",
        "outputId": "11c30208-a273-4d0a-e4f2-5db687d6482a"
      },
      "outputs": [],
      "source": [
        "#global sports\n",
        "predict_df[predict_df['class']==5]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
